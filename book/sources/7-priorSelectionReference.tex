% !TEX root = ../script.tex
\section{Опорное априорное распределение}
\label{sec:reference_prior}

\subsection{Определение опорного априорного распределения}

В конце предыдущей главы мы увидели, что априорное распределение Джеффриса не годится, если размерность пространства параметров $\pD > 1$.
Существуют альтернативный подход к выбору неинформативного априорного распределения, который подходит и для больших размерность.
В этой главе мы рассмотрим такой подход, априорные распределения, которые получаются в результате его использования, называются
\emph{опорными априорными распределениями}.

Пусть $X \sim p(x | \theta)$ и $T(X)$ --- достаточная статистика для $\theta$.
Мы хотим, чтобы априорное распределение $\pi(\theta)$ и апостериорное распределение $p(\theta | t)$ для фиксированного значения достаточной статистики $t$были максимально далеки друг от друга --- то есть,
чтобы априорное распределение привносило в статистический вывод как можно меньше информации.
Для этого будем максмизировать расстояние Кульбака-Лейблера, которое имеет вид:
\[
\mathrm{KL}(p(\theta | t) | \pi(\theta)) = \int_{\theta \in \Theta} p(\theta | t) \log \frac{p(\theta | t)}{\pi(\theta)} d\theta.
\]

Нам хотелось бы максимизировать такое расстояния не для одного фиксированного значения $t$, а по всем $t$ --- причем, взвесить разные $t$ разумно,
используя маргинальное распределение $p(t)$:
\[
\mathrm{MI}_{\pi(\theta)}(\Theta, T) = \int p(t) \int p(\theta | t) \log \frac{p(\theta | t)}{\pi(\theta)} d\theta dt \rightarrow \max.
\]
Такое усреднение $\mathrm{MI}(\Theta, T)$ называют взаимной информацией.
В таких обозначениях искомое опорное априорное распределение будет решением следующей вариационной задачи:
\[
\pi^*(\theta) = \mathrm{arg} \max_{\pi(\theta)} \mathrm{MI}_{\pi(\theta)}(\Theta, T).
\]

Однако часто аналитическое решение такой вариационной задачи получить невозможно.

\subsection{Вычисление опорного априорного распределения}

Определение опорного априорного распределения, введенное выше,
рассматривает статистику $T(x)$ как функцию одного наблюдения.
Давайте вместо этого рассмотрим вектор $\mathbf{T}^k$,
включащий значения статистик, полученные с помощью $k$ независимых наблюдений из распределения $p(x| \theta)$.

Введем обозначения:
\begin{align*}
\mathrm{MI}_{\pi(\theta)}(\Theta, \mathbf{T}^k) &= \int p(\mathbf{t}^k) \int p(\theta | \mathbf{t}^k) \log \frac{p(\theta | \mathbf{t}^k)}{\pi(\theta)} d\theta d\mathbf{t}^k, \\
\pi_k(\theta) &= \mathrm{arg} \max_{\pi(\theta)} \mathrm{MI}_{\pi(\theta)}(\Theta, \mathbf{T}^k).
\end{align*}

Затем мы получим неинформативное априорное распределение, устремив $k$ к бесконечности:
\[
\pi^*(\theta) = \lim_{k \rightarrow \infty} \pi_k(\theta).
\]

Перепишем $\mathrm{MI}_{\pi(\theta)}(\Theta, \mathbf{T}^k)$ в виде:
\[
\mathrm{MI}_{\pi(\theta)}(\Theta, \mathbf{T}^k) = \int \pi(\theta) \log \frac{f_k(\theta)}{\pi(\theta)} d\theta,
\]
где 
\[
f_k(\theta) = \exp \left(\int p(\mathbf{t}^k | \theta) \log p(\theta | \mathbf{t}^k) d \mathbf{t}^k \right).
\]
В решении этой вариационной задачи у нас есть дополнительное ограничение $\int \pi(\theta) d\theta = 1$.
Следовательно, Лагранджиан имеет вид:
\[
\pi_k(\theta) = \sup_{\pi(\theta)} \int \pi(\theta) \log \frac{f_k(\theta)}{\pi(\theta)} d\theta + \lambda \left(\int \pi(\theta) d\theta - 1 \right).
\]
Используя вариационное исчисление, мы получаем:
\[
\pi^*_k(\theta) \propto f_k(\theta).
\]

Не будем здесь приводить полного решения этой вариационной задачи.
Получим только доказательство того, что 
\[
\pi^*_k(\theta) = f_k(\theta).
\]
в дискретном случае.
\begin{proof}
Пусть $T$ и $\theta$ --- дискретны, тогда
\[
\pi^*_k(\theta) = \argmax_{\pi(\theta)} \sum_i \pi_i \frac{q_i}{\pi_i} + \lambda \left(\sum_i \pi_i - 1\right),
\]
здесь $\pi_i$ --- вероятности $\pi(\theta_i)$, $q_i = f_k(\theta_i)$.
Дифференцируя по $\pi_i$, получаем необходимое условие экстремума:
\begin{align*}
\frac{\partial}{\partial \pi_j} \left[ \sum_i \pi_i \frac{q_i}{\pi_i} + \lambda \left(\sum_i \pi_i - 1\right)\right] &= \log (q_j / \pi_j) + \pi_j (q_j / \pi_j)^{-1} (-q_j / \pi_j^2) + \lambda= \\
&= -1 -\log \pi_j + \log q_j + \lambda = 0.
\end{align*}
Следовательно,
\[
\log \pi_j = \log q_j + \lambda - 1.
\]
Таким образом,
\[
\pi_j = q_j e^{\lambda - 1}.
\]
Тогда 
\[
\pi = q,
\]
что и требовалось доказать.
\end{proof}

Мы свели исходную задачу к задаче вычисления интеграла 
\[
f_k(\theta) = \exp \left(\int p(\mathbf{t}^k | \theta) \log p(\theta | \mathbf{t}^k) d \mathbf{t}^k \right).
\]
К тому же нужно найти асимптотический предел для $k \rightarrow \infty$.
Если мы устремим размер выборки к бесконечности,
апостериорное распределение $p(\theta| \mathbf{t}^k) $ будет близко к нормальному,
причем среднее этого нормального распределения будет соответствовать 
истинному значению оцениваемого параметра.

Формально близость апостериорного распределения к нормальному и 
сходство Байесовских и классических оценок параметров
описывает теорема Бернштейна-фон Мизеса.
\index{теорема Бернштейна-фон Мизеса}

\begin{Theorem}[Теорема Берншейтна-фон Мизеса]
Пусть для задачи статистического оценивания выполнен ряд условий регулярности: классическая эффективная оценка $\estTk$ асимптотически нормальна, и априорное распределение ведет себя достаточно регулярно, в частности в окрестности истинного значения параметра $\theta_0$.
Обозначим $\mathbf{t}^k$ вектор независимых $t^k_j$ из распределения $p(t| \theta)$. Тогда
\begin{equation}
\label{eq:bvm}
\|p(\theta | \mathbf{t}^k) - \mathcal{N}(\estTk, I_k^{-1}(\theta_0))\| \rightarrow 0,
\end{equation}
где $I_k(\theta_0)$ --- информация Фишера\index{информация Фишера} для $\theta_0$, сходимость понимается в смысле сходимости по вероятности, а $\|\cdot\|$ обозначает расстояние по вариации.
\end{Theorem}

Докажем теперь, используя теорему Бернштейна-фон Мизеса, что опорное априорное распределение совпадает с априорным распределением Джеффриса в одномерном случае.

\begin{proof}
Любая асимптотически эффективная оценка $\estTk$ является асимптотически достаточной.
Следовательно, мы можем заменить в \eqref{eq:bvm} $\mathbf{t}^k$ на $\estTk$:
\[
\|p(\theta | \estTk) - \mathcal{N}(\estTk, I_k^{-1}(\theta_0))\| \rightarrow 0.
\]
Для $y \sim \mathcal{N}(\estTk, I_k^{-1}(\theta_0))$ плотность имеет вид:
\[
p(y) = \sqrt{I_k(\theta_0)} \exp \left(-\frac{I_k(\theta_0)}{2} (y - \estTk)^2 \right).
\]

Для независимых наблюдений $I^{-1}_k(\theta_0) = \frac{1}{k} I^{-1}(\theta_0)$.
Таким образом,
\[
p(\theta | \estTk) \propto \sqrt{k I(\theta_0)} \exp \left(-\frac{k I(\theta_0)}{2} (y - \estTk)^2 \right).
\]
Оценка $\estTk$ --- состоятельна, следовательно для больших $k$:
\[
p(\theta | \estTk) \propto \sqrt{k I(\estTk)} \exp \left(-\frac{k I(\estTk)}{2} (y - \estTk)^2 \right).
\]

Далее будем действовать менее формально.
Полное доказательство есть, например, в статье~\cite{bernardo2005reference}.

Рассмотрим $\theta = \theta_0$:
\begin{align*}
p(\theta_0 | \estTk) &\propto \sqrt{k I(\theta_0)} \exp \left(-\frac{k I(\estTk)}{2} (\theta_0 - \estTk)^2 \right) \approx \\
&\approx \sqrt{k I(\theta_0)} \exp \left(-\frac{k I(\estTk)}{2} (\theta_0 - \theta_0)^2 \right) = \sqrt{k I(\theta_0)}.
\end{align*}

Следовательно, искомый интеграл для больших $k$ можно аппроксимировать:
\[
f_k(\theta) \approx \exp \left(\int p(\mathbf{t}^k | \theta) \log \sqrt{I(\theta)} d \mathbf{t}^k \right).
\]
$\sqrt{I(\theta)}$ не зависит от $\mathbf{t}^k$, 
а интеграл по вероятностной плотности --- единица.
Следовательно, 
\[
f_k(\theta) \approx \sqrt{I(\theta)}.
\]
Получается, что опорное априорное распределение распределение совпадает с априорным распределением Джеффриса в одномерном случае.
\end{proof}


\begin{example}[Опорное априорное распределение для экспоненциального распределения]
Пусть $x_i \sim \mathrm{Exp}(\theta)$.
Достаточная статистика для $\theta$ --- среднее выборки $\overline{x} = \frac{1}{\sS} \sum_{i = 1}^\sS x_i$.
Оценка максимума правдоподобия есть $\mleT = \frac{1}{\overline{x}}$.

Для одномерного случая мы могли бы получить опорное априорное распределение из априорного распределения Джеффриса.
Но давайте вместо этого воспользуемся подходом, описанном выше.

Пусть $\vecX = \{x_1, \ldots, x_\sS \}$. Тогда правдоподобие:
\[
p(\vecX | \theta) = \theta^{\sS} \exp \left(-\sS \overline{x} \theta\right).
\]

В соответствии с теоремой Бернштейна-фон Мизеса апостериорное распределение для $\sS \rightarrow \infty$ не зависит от априорного распределения, поэтому возьмем для удобства равномерное априорное распределение.

В силу концентрации для больших выборок для достаточной статистики $\mleT$:
\[
p(\mleT | \theta) \approx \delta(\mleT - \theta).
\]
Следовательно,
\[
f_k(\theta) \approx \exp \left[\log p(\theta | \mleT) \right] = p(\theta | \mleT).
\]

Получим апостериорное распределение по формуле Байеса:
\[
p(\theta | \mleT) = \frac{p( \mleT | \theta) \pi(\theta)}{p(\mleT)}.
\]
Априорное распределение --- равномерное, правдоподобие 
\[
p(\mleT | \theta) \propto \theta^{\sS} \exp \left(-\sS \frac{\theta}{\mleT} \right),
\]
а маргинальное распределение 
\[
p(\mleT) = \int p(\mleT | \theta) \pi(\theta) d\theta = \int \theta^\sS \exp \left(-\sS \frac{\theta}{\mleT} \right) d\theta = \Gamma(\sS + 1) \left(\frac{\mleT}{\sS} \right)^{\sS + 1}.
\]

Подставляя эти выражения в исходную формулу, получаем:
\[
\pi_\sS(\theta) = \left. \left(\frac{\sS}{\mleT}\right)^{\sS + 1} \frac{1}{\Gamma(\sS + 1)} \theta^\sS \exp \left(- \frac{\sS \theta}{\mleT} \right) \right|_{\mleT = \theta} \propto \frac{1}{\theta}.
\]
Здесь мы использовали $\mleT = \theta$ в силу того, что выполнена теорема Бернштейна-фон Мизеса.
\end{example}

Проверим теперь, что опорное априорное распределение 
инвариантно к репараметризации --- даже если не выполнены условия регулярности, при выполнении которых опорное априорное распределение совпадает с априорным распределением Джеффриса.
\begin{proof}
Нам нужно проверить, что взаимная информация не зависит от параметризации:
\begin{align*}
\mathrm{MI}_{\pi(\theta)}(\Theta, \mathbf{T}^k) &= \int p(\mathbf{t}^k) \int p(\theta | \mathbf{t}^k) \log \frac{p(\theta | \mathbf{t}^k)}{\pi(\theta)} d\theta d\mathbf{t}^k = \\ &= \int p(\mathbf{t}^k) \int p(\phi | \mathbf{t}^k) \log \frac{p(\phi | \mathbf{t}^k)}{\pi(\phi)} d\phi d\mathbf{t}^k
\end{align*}
При использовании другой параметризации плотность распределения нужно домножить на Якобиан:
\begin{align*}
p(\phi) &= p(\theta(\phi)) \left|\frac{d \theta}{d \phi} \right| \\
p(\phi | \mathbf{t}^k) &= p(\theta(\phi) | \mathbf{t}^k) \left|\frac{d \theta}{d \phi} \right|
\end{align*}
Следовательно, отношение априорной и апостериорной плотностей не зависит от параметризации --- Якобиан сокращается.
Якобиан в $p(\phi | \mathbf{t}^k)$ сокращается в силу формулы для замены переменных под интегралом.
Таким образом, внутренний интеграл не меняется, а, значит, не меняется и взаимная информация.
\end{proof}

\subsection{Примеры опорных априорных распределений}

\begin{example}
Рассмотрим класс плотностей 
\[
M = \{f(x - \theta) : x \in \bbR, \theta \in \bbR \}.
\]
Для такого класса плотностей зададим опорное априорное распределение $\pi(\theta)$.

Для фиксированного $\theta$ и случайной величины из распределения $f(x - \theta)$ пусть $y = x + a, \nu = \theta + a$.
Определим $f'(y) = f(y - a - \theta)$.
Рассмотрим семейство плотностей $M'$, эквивалентное $M$:
\[
M' =\{f'(y - \nu): y \in \bbR, \nu \in \bbR \}.
\]
Так как Якобиан сдвига равен единице, и плотность априорного распределения 
не зависит от сдвига, то $\pi'(\nu) = \pi(\theta)$.
В силу инвариантности опорного априорного распределения относительно 
репараметризации $\pi'(\nu) = \pi(\theta + a)$.
Следовательно, $\pi(\theta + a) = \pi(\theta)$ для произвольного $a$.
Таким образом, опорное априорное распределение для одномерного параметра сдвига будет равномерным.
\end{example}

\begin{example}
Рассмотрим теперь одномерный параметр масштаба.
Определим семейство 
\[
S = \left\{\frac{1}{\theta} f \left( \frac{x}{\theta} \right) : x > 0, \theta > 0 \right\}.
\]
Взяв $y = \log x$, $\phi = \log \theta$, определим эквивалентное семейство плотностей:
\[
S' = \{f(\exp(y - \phi)): y \in \bbR, \phi \in \bbR \}.
\]
Мы получили семейство распределений, для которого $\phi$ --- параметр сдвига. 
В силу результата, полученного в предыдущем примере, $\pi'(\phi)$ --- равномерное.
Выполнено, что 
\[
\pi'(\phi) = \theta \pi(\theta).
\]
Следовательно, опорное априорное распределение для параметра масштаба:
\[
\pi(\theta) \propto \frac{1}{\theta}.
\]
\end{example}

\subsection{Использование метода Монте-Карло для получения опорного априорного распределения}

Опорное априорное распределение имеет вид:
\[
f_k(\theta) = \exp \left\{\int p(\mathbf{t}^k | \theta) \log \left( \frac{p(\mathbf{t}^k | \theta) h(\theta)}{\int p(\mathbf{t}^k | \theta) h(\theta) d \theta}\right) d \mathbf{t}^k \right\},
\]
где $h(\theta)$ --- исходное априорное распределение, от которого результат зависеть не будет.

Аналитически получить опорное априорное распределение получится только в нескольких случаях, поэтому используют приближенные подходы.
Один из самых популярных --- методы на основе идеи Монте-Карло.
Пускай $\{x^{(i)}\}$ --- выборка независимых одинаково распределенных случайных величин из распределения $p(x)$.
Тогда для функции $f(x)$ можно оценить интеграл $\int f(x) p(x) dx$ как:
\[
\bbE f(x) = \int f(x) p(x) dx \approx \frac{1}{\sS} \sum_{i = 1}^{\sS} f(x^{(i)}).
\]
Сходимость будет, например, в силу закона больших чисел.

Предложим алгоритм сэмплирования из опорного априорного распределения на основе идеи Монте-Карло.

% \begin{algorithmic}
% \If {$i\geq maxval$}
%     \State $i\gets 0$
% \Else
%     \If {$i+k\leq maxval$}
%         \State $i\gets i+k$
%     \EndIf
% \EndIf
% \end{algorithmic}