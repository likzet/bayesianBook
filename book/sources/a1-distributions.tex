% !TEX root = ../script.tex
\section{Основные вероятностные распределения}

\subsection{Многомерное нормальное распределение}
\label{sec:gauss}
\index{распределение!многомерное нормальное}

Многомерное нормальное распределение или гауссовское распределение --- такое вероятностное распределение $p(\vecX | \vecMu, \Sigma)$ на $\vecX \in \bbR^\iD$, что его плотность имеет вид:
\[
p(\vecX | \vecMu, \Sigma) = \frac{1}{(2 \pi)^{\iD / 2} |\Sigma|^{1 / 2}}
\exp \left\{- \frac12 (\vecX - \vecMu)^{\mathrm{T}} \Sigma^{-1} (\vecX - \vecMu) \right\}.
\]
Два набора параметров распределения --- вектор $\vecMu$ и матрица $\Sigma$ --- определяют его среднее значение и ковариационную матрицу соответственно.
Такое распределение обозначают $\mathcal{N}(\vecMu, \Sigma)$.

У нормального распределения множество замечательных свойств, о которых можно прочитать в отдельных главах этой книги или в более общих книгах, таких как книга Бишопа~\cite{bishop2006pattern}.

\subsection{Распределение Дирихле}
\label{sec:dirichlet}
\index{распределение!Дирихле}

Носитель распределение Дирихле --- симплекс.
Для $k$-мерного распределения Дирихле симплекс есть множество точек, для которых:
\[
S_k = \left\{ \vecX: \sum_{i = 1}^k x_i = 1, x_i \geq 0, i \in \{1, \ldots, k\} \right\}.
\]
Легко видеть, что существует взаимнооднозначное соотвествие между вероятностными распределениями на конечном множестве $\{1, \ldots, k\}$ и точками такого симплекса.

Плотность распределения Дирихле с вектором параметров $\vecA \in \bbR_+^k (\alpha_i \geq 0)$ есть:
\[
p(\vecX | \vecA) \propto x_1^{\alpha_1 - 1} \cdot \ldots \cdot x_k^{\alpha_k - 1}.
\]

Получим нормировочный коэффициент для такого распределения:
\[
\int_{\vecX \in S_k} x_1^{\alpha_1 - 1} \cdot \ldots \cdot x_k^{\alpha_k - 1} d\vecX = \frac{\prod_{i = 1}^k \Gamma(\alpha_i)}{\Gamma(\sum_{i = 1}^k \alpha_k)},
\]
здесь $\Gamma(a) = \int_{0}^{\infty} t^{a - 1} e^{-t} dt$ --- гамма функция, $\Gamma(n + 1) = n!$ для $n \in \mathbb{N}$ и $\Gamma(a + 1) = a \Gamma(a)$.

Если мы рассмотрим $k = 2$, то получим бета-распределение.
В частности, выполнено, что:
\[
\int_0^1 \theta^{\alpha_1 - 1} (1 - \theta)^{\alpha_2 - 1} d\theta =  \frac{\Gamma(\alpha_1) \Gamma(\alpha_2)}{\Gamma(\alpha_1 + \alpha_2)}.
\]

\begin{example}
Найдем среднее бета-распределения.
\begin{align*}
\bbE x &= \int_0^1 \theta \frac{\Gamma(\alpha_1 + \alpha_2)}{\Gamma(\alpha_1) \Gamma(\alpha_2)} \theta^{\alpha_1 - 1} (1 - \theta)^{\alpha_2 - 1}d\theta = \\
&= \frac{\Gamma(\alpha_1 + \alpha_2)}{\Gamma(\alpha_1) \Gamma(\alpha_2)} \int_0^1 \theta^{\alpha_1 + 1 - 1} (1 - \theta)^{\alpha_2 - 1}d\theta = \\
&= \frac{\Gamma(\alpha_1 + \alpha_2)}{\Gamma(\alpha_1) \Gamma(\alpha_2)} 
   \frac{\Gamma(\alpha_1 + 1) \Gamma(\alpha_2)}{\Gamma(\alpha_1 + \alpha_2 + 1)} = \frac{\alpha_1}{\alpha_1 + \alpha_2}.
\end{align*}
Для распределения Дирихле с вектором параметров $\vecA$ математическое ожидание равно $\bbE x_j = \frac{\alpha_j}{\sum_{i = 1}^k \alpha_k}$.

\end{example}

\subsection{Экспоненциальное семейство распределений}
\label{sec:exp_family}
\index{экспоненциальное семейство распределений}
% http://www.cs.columbia.edu/~jebara/4771/tutorials/lecture12.pdf
% https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter8.pdf

В этом разделе определим экспоненциальное семейство распределений и получим ряд его полезных свойств.
\begin{Definition}
Будем говорить, что распределение принадлежит экспоненциальному семейству, если
его плотность (относительно меры Лебега) имеет вид:
\[
p(\vecX | \vecT) = h(\vecX) \exp \left(\vecT^\T T(\vecX) - A(\vecT) \right).
\]
\end{Definition}

Параметризация $\vecT$, для которой правдоподобие имеет такой вид, называется канонической, 
а вектор $T(\vecX)$ --- вектор достаточных статистик для модели, то есть такая функция данных $\vecX$, что
условное распределение $P(\vecX | \vecT)$ совпадает с условным распределением $P(\vecX | T, \vecT)$.
Эквивалентное утверждение, необходимое и достаточное условие того, что статистика является достаточной: $P(\vecT | \vecX, T) = P(\vecT | T)$.

Экспоненциальному семейству распределений принадлежат почти все используемые в математической статистике распределения: нормальное, биномиальное, Пуассоновское.
Среди известных распределений, которые не принадлежат этому семейству распределений, --- распределение Коши.

Приведем два примера экспоненциального семейства, канонических параметризаций и достаточных статистик для них.
\begin{example}
Рассмотрим распределение Бернулли, определенное на $x \in \{0, 1\}$.
\begin{align*}
p(x | \alpha) &= \alpha^{x} (1 - \alpha)^{1 - x} = \\
&= \exp \left[\log (\alpha^{x} (1 - \alpha)^{1 - x}) \right] = \\
&= \exp \left[x \log \alpha + (1 - x) \log (1 - \alpha)) \right] = \\
&= \exp \left[x \log \frac{\alpha}{1 - \alpha} + \log (1 - \alpha)) \right] = \\
&= \exp \left[x \theta - \log (1 + e^{\theta})\right].
\end{align*}
Для распределения Бернулли 
\[
T(x) = x, \theta = \log {\alpha}{1 - \alpha}, A(\theta) = \log (1 + e^{\theta}).
\]
\end{example}

Покажем теперь, что нормальное распределение тоже принадлежит экспоненциальному семейству
\begin{example}
\begin{align*}
p(x) &= \frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{1}{2 \sigma^2} (x - \mu)^2 \right) =\\
     &= \frac{1}{\sqrt{2 \pi}} \exp \left(-\log \sigma - \frac{x^2}{2 \sigma^2} + \frac{\mu x}{\sigma^2} - \frac{\mu^2}{2 \sigma^2} \right) = \\
    &= \frac{1}{\sqrt{2 \pi}} \exp \left( \vecT^\T T(x) - \log \sigma - \mu^2 / (2 \sigma^2) \right),
\end{align*}
$h(x) = \frac{1}{\sqrt{2 \pi}}$, $A(\vecT) = \log \sigma + \mu^2 / (2 \sigma^2)$.
Получаем достаточные статистики:
\[
T(x) = \begin{pmatrix}
x \\
x^2 
\end{pmatrix}
\]
Каноническую параметризацию:
\[
\vecT = \begin{pmatrix}
\mu / \sigma^2 \\
-1 / (2 \sigma^2)
\end{pmatrix}
\]
Компонента $A(\theta)$ имеет следующий вид как функция от канонических параметров:
\[
A(\theta) = \frac{\mu}{2 \sigma^2} + \log \sigma = - \frac{\theta_1^2}{4 \theta_2} - \frac12 \log (-2\theta_2).
\]
\end{example}

Приведем еще три важных свойства распределений из этого семейства.
\begin{Theorem}
\label{th:exponential_derivative}
\[
\frac{d A(\vecT)}{d \vecT} = \bbE_{p_{\vecT}} T(\vecX).
\]
\end{Theorem}
\begin{proof}
Используя то, что интеграл плотности вероятностного распределения равен $1$, получим:
\[
A(\vecT) = \log \left[\int_{\bbR^{\iD}} h(\vecX) \exp( \vecT^\T T(\vecX)) d \vecX \right].
\]
Обозначим $Q(\vecT) = \int_{\bbR^{\iD}} h(\vecX) \exp( \vecT^\T T(\vecX)) d \vecX$.
Подсчитаем производную:
\begin{align*}
\frac{d A(\vecT)}{d \vecT} &= \frac{1}{Q(\vecT)} \frac{d Q(\vecT)}{d \vecT} = \frac{Q'(\vecT)}{Q(\vecT)} = \\
&= \frac{\int_{\bbR^{\iD}} h(\vecX) \exp( \vecT^\T T(\vecX)) T(\vecX) d \vecX}{\int_{\bbR^{\iD}} h(\vecX) \exp( \vecT^\T T(\vecX)) d \vecX} = \\
&= \frac{\int_{\bbR^{\iD}} h(\vecX) \exp( \vecT^\T T(\vecX) - A(\vecT)) T(\vecX) d \vecX}{\int_{\bbR^{\iD}} h(\vecX) \exp( \vecT^\T T(\vecX) - A(\vecT)) d \vecX} = \\
&= \int_{\bbR^{\iD}} h(\vecX) \exp( \vecT^\T T(\vecX) - A(\vecT)) T(\vecX) d \vecX = \\
&= \bbE_{p_{\vecT}} T(\vecX).
\end{align*}
Получается, что мы явно можем выразить эту производную как математическое ожидание достаточной статистики:
\[
\frac{d A(\vecT)}{d \vecT} = \bbE_{p_{\vecT}} T(\vecX).
\]
\end{proof}
\begin{Theorem}
Функция $A(\vecT)$ выпуклая.
\end{Theorem}
\begin{proof}
Если мы возьмем вторую производную, то получим:
% TODO вставить вывод
\[
\frac{d^2 A(\vecT)}{d \vecT^2} = \mathrm{Cov}_{p_{\vecT}} T(\vecX).
\]
Ковариационная матрица случайного вектора $\mathrm{Cov}_{p_{\vecT}} T(\vecX)$ неотрицательно определена.
Поэтому функция $A(\vecT)$ выпуклая.
\end{proof}

Наконец обозначим $\vecMu = \bbE T(\vecX)$.
\begin{Theorem}
Пусть мы наблюдаем выборку независимых одинаково распределенных случайных величин $D = \{x_1, \ldots, x_n\}$.
Тогда оценка максимума правдоподобия $\hat{\vecMu}_{MLE}$:
\[
\hat{\vecMu}_{MLE} = \frac{1}{n} \sum_{i = 1}^{n} T(x_i).
\]
\end{Theorem}
\begin{proof}
Используем утверждение~\ref{th:exponential_derivative} и явно дифференцируем плотность.
\end{proof}

Отметим, что оценки максимума правдоподобия $\hat{\vecMu}_{MLE}$ будут несмещенными и эффективными (для них будет выполнено неравенство Рао-Крамера).
% TODO написать про это