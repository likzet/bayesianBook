% !TEX root = ../script.tex
\section{Идеи Байесовской статистики}

\subsection{Проблематика Байесовского подхода}

Пусть мы наблюдаем случайную величину $x \in X$ из условного распределения $p(x | \theta)$.
В Байесовской статистике мы будем считать, что $\theta \in \Theta$ --- тоже случайная величина. 
Пока будем считать, что $x$ и $\theta$ --- непрерывные случайные величины.

Классическая задача статистического оценивания заключается в оценке параметра $\theta$ по наблюдениям.
Аналогичная задача решается и в Байесовской статистике --- но теперь нас интересует не просто оценка $\hat{\theta}$,
а все распределение $p(\theta|x)$.

Это \emph{апостериорное распределение} может быть получено из правдоподобия $p(x| \theta)$, априорного распределения $\pi(\theta)$ и маргинального распределения $p(x)$
с использованием формулы Байеса:
\[
p(\theta | x) = \frac{p(x| \theta) \pi(\theta)}{p(x)}.
\]
Так как знаменатель не зависит от $\theta$ часто удобно работать только с числителем, произведением правдоподобия на плотность априорного распределения:
\[
p(\theta | x) \propto p(x| \theta) \pi(\theta).
\]

Таким образом, мы ввели следующие объекты:
\begin{itemize}
	\item априорное распределение $\pi(\theta)$,
	\item правдоподобие $p(x| \theta)$,
	\item апостериорное распределение $p(\theta | x)$,
	\item маргинальное распределение $p(x) = \int p(x| \theta) \pi(\theta) d\theta$.
\end{itemize}

В классической статистике мы предполагаем, что задана модель данных,
которая определяет правдоподобие $p(x| \theta)$.
И на основании этого распределения мы делаем оценку $\hat{\theta}$.
В Байесовской статистике для того, чтобы полностью задать вероятностную модель, этого оказывается недостаточно:
нам нужно еще определить априорное распределение данных.

Пожалуй, наибольшее внимание в этом пособии мы уделим именно выбору априорного распределения.
Грубо все подходы к выбору априорного распределения можно разбить на три пересекающихся группы:
субъективный подход, объективный подход и прагматичный подход.

В субъективном подходе мы считаем, что эксперты в предметной области дали дам готовое априорное распределение, и нам его выбирать не нужно.
Таким образом, в этом случае априорное распределение уже задано и нам его выбирать не нужно.
Однако, обычно это не так.

В объективном подходе к выбору априорного распределения мы хотим минимизировать влияние априорного распределения
на наши выводы.
Таким образом, нужно выбрать такое априорное распределение, у которого будут одинаковые предпочтения ко всем $\theta \in \Theta$.
Возникновение объективного подхода связано с тем, что основным направлением развития математической статистики 
были вероятностные методы, и альтернативы должны были в первую очередь давать правильные в смысле этого основного направления результаты.
Примерами объективного подхода является априорное распределение Джеффриса и опорное априорное распределение.
Так как индифферентность можно понимать по-разному, в этом подходе существует несколько техник.
Мы уделим объективному подходу, пожалуй, наибольшее внимание в этом пособии.

В прагматичном подходе нам в первую очередь интересно наличие определенных свойств у полученной оценки --- 
например, ее численная устойчивость или разреженность.
Выбор априорного распределения позволяет гарантировать некоторые такие свойства,
поэтому часто Байесовские методы используют, например, для регуляризации.

\subsection{Объективный Байесовский подход}
\label{sec:objective_intro}

Формулу Байеса знали --- и скорее всего открыли примерно одновременно --- Лапласа и Байес. 
Так как они смотрели на нее с классической точки зрения,
то первым их порывом было выбрать в качестве априорного распределения то, 
которое обеспечит минимальное влияния на апостериорное распределение.

Естественный кандидат в таком случае --- равномерное распределение на $\Theta$.
То есть, $\pi(\theta) \propto c$.
В таком случае 
\[
p(\theta | x) \propto p(x | \theta),
\]
и мы будем получать одинаковые результаты с использованием методов, которые работают непосредственно с правдоподобием и с апостериорным распределением.

Однако, такое априорное распределение решает нашу проблему только в узком смысле.
Если мы рассмотрим взаимно-однозначное преобразование случайной величины $\theta$, равномерно распределенной на $\Theta = [0, 1]$, например,
\begin{align*}
\rho &= \frac{\theta}{1 - \theta}, \rho \in (0, \infty), \\
   r &= \log \left( \frac{\theta}{1 - \theta} \right), r \in [0, 1], \\
\end{align*}
мы получим, что априорные распределения $\pi(\rho)$ и $\pi(r)$ уже не будут равномерными.

Таким образом, выбор в качестве априорного распределения равномерного не обеспечивает на самом деле 
отсутствие предпочтений к различным значениям параметра.

Этот пример и подобные ему привели к тому, что Байесовский подход в статистике практически не использовался.
Фишер, Нейман, Вальд и Колмогоров строили математическую статистику, в которой не было места априорным распределениям.
Однако, со времени стало понятно, что на самом деле Байесовская и классическая статистики изучают одно и то же, 
но с разных сторон --- подобно тому, как часть физиков в девятнадцатом веке считали, что свет это частица,
а другая часть --- что это волна.

Оказалось, что Байесовский подход можно формализовать в рамках теории принятия решений.
Кроме того, реабилитации Байесовского подхода в математической статистике поспособствовали 
два фундаментальных открытия: 
Де Финетти удалось показать, что удачный выбор априорного распределения позволяет представить в новом виде задачу оценки свойств параметра, 
а Джеффрису удалось развить идеи Лапласа и определить априорные распределения, которые минимально бы влияли на апостериорное распределение.
Де Финетти оправдал использование субъективного подхода в Байесовской статистике, 
а Джеффрис по новому взглянул на объективный подход.
Пожалуй, еще более важным фактором, повлиявшим на развитие Байесовских идей, стало их повсеместное использование для решения прикладных задач,
в том числе в машинном обучении.

% Задана \emph{выборка данных} $X = \{\vecX_i \}_{i = 1}^{\sS{}}$, $\vecX_i \in \mathbb{X} \subseteq \bbR^{\iD{}}$.
% Предполагается, что вероятностное распределение $p(X) = p(X|\vecT)$ определяется \emph{неизвестным вектором параметров} $\vecT \in \Theta \subseteq \bbR^{\pD{}}$.
% Примеры задач статистического оценивания:
% \begin{itemize}
%   \item оценка вектора параметров $\vecT$ и получение свойств такой оценки,
%   \item оценка вероятности того, что вектор параметров $\vecT$ лежит в заданном множестве $\Theta_0$,
%   \item построение такого множества $\Theta_0$ минимального объема, в котором $\vecT$ лежит не меньше чем с заданной вероятностью.
%   \item выбор модели, то есть множества $\Theta_0$ из нескольких альтернатив.
% \end{itemize}

% В статистике рассматривают модели, которые обладают набором <<хороших>> свойств и хорошо исследованы.
% Пример такой модели --- \emph{экспоненциальное семейство распределений}.
% Пусть наблюдения $\vecX_i$ из выборки независимые и одинаково распределены с плотностью $p(\vecX|\vecT)$.
% Тогда семейство распределений, параметризуемых $\vecT \in Theta$, называется экспоненциальным семейством, если
% \[
% p(\vecX| \vecT) = \exp \left(c(\vecT) + \sum_{j = 1}^{\pD{}} t_j(\vecX) A_j(\vecT) \right) h(\vecX),
% \]
% где $c(\cdot)$, $A_j(\cdot)$ зависят только от $\vecT$, и $t_j(\cdot)$ зависят только от $\vecX$.
% Экспоненциальному семейству распределений принадлежит нормальное распределение, распределение Бернулли, распределение Пуассона и многие другие.

% Семейство распределений называется \emph{регулярным}, если
% \begin{itemize}
% \item Носитель распределения не зависит от $\vecT$,
% \item функция плотности $p(\vecX| \vecT)$ $3$ раза непрерывно дифференцируема по $\vecT$,
% \item можно дифференцировать под интегралом.
% \end{itemize}

% Регулярное семейство распределений включает в себя экспоненциальное семейство распределений.

% Фундаментальную роль в математической статистике играет правдоподобие и его логарифм:
% \[
% L(X, \vecT) = L(\vecT) = \log p(X| \vecT).
% \]
% Здесь и в дальнейшем для удобства мы опускаем $X$ в списке аргументов логарифма правдоподобия.

% Оценка максимального правдоподобия имеет вид:
% \[
% \mleT = \argmax_{\vecT \in \Theta} L(\vecT).
% \]
% При выполнение определенных условий регулярности такая оценка оказывается оценкой, которая имеет минимальную дисперсию среди всех возможных оценок и сходится к истинному значению $\vecT^*$.

% Отметим, что оценка максимального распределения тесно связана с расстоянием Кульбака-Лейблера.
% Пусть заданы два непрерывных распределения $p(\vecT)$ и $q(\vecT)$. 
% Тогда \emph{расстояние Кульбака-Лейблера} между ними имеет вид:
% \[
% \KuLi(p|q) = -\int p(\vecT) \ln \left( \frac{q(\vecT)}{p(\vecT)} \right) d\vecT.
% \]
% Расстояние Кульбака-Лейблера не является расстоянием, в частности, вообще говоря, $\KuLi(p|q) \neq \KuLi(q|p)$.
% Однако, $\KuLi(p|q) \geq 0$ и равно нулю тогда и только тогда, когда $p = q$.


\subsection{Теорема де Финетти}

Пускай случайные величины $\vecX_i$ таковы, что их совместная функция распределения не меняется  в случае произвольной перестановки элементов выборки $\Sample = \{x_i\}_{i = 1}^{\sS}$:
\[
P(x_1 \leq y_1, \ldots, x_{\sS} \leq y_{\sS}) = P(x_1 \leq y_{i_1}, \ldots, x_{\sS} \leq y_{i_\sS}).
\]
Такой набор случайных величин будем называть перестановочным.
Будем говорить, что последовательность $x_i, i = 1, 2, \ldots, \sS, \sS + 1, \ldots$ бесконечно перестановочна, если для любого $\sS > 1$ выполнено, что $x_1, \ldots, x_{\sS}$ перестановочна.

\begin{Theorem}
Пусть $x_i$ составляют бесконечную перестановочную последовательность, и каждое $x_i$ принимает значения $0$ или $1$. 
Тогда для некоторого распределения $\pi(\theta)$ выполнено, что
\[
P(x_1 = y_1, \ldots, x_{\sS} = y_{\sS}) = \int_{0}^1 \theta^{\sum_{i = 1}^{\sS} y_i} (1 - \theta)^{\sS - \sum_{i = 1}^{\sS} y_i} d \pi(\theta)
\]
для произвольного $\sS$ и набора $y_i \in \{0, 1\}$.
То есть, для заданного $\theta$ выполнено, что $x_1, \ldots, x_{\sS}$ --- условно независимые одинаково распределенные Бернуллевские случайные величины  с параметром $\theta$, и априорное распределение $\theta$ --- $\pi(\theta)$.
\end{Theorem}

Приведенная теорема может быть обобщена на случай, если множество значений, которые принимают $x_i$ не ограничиваются $0$ и $1$.
Связь между приведенной выше теоремой Де Финетти и теоремой Де Финетти общего вида примерно такая же, как между теоремой Муавра-Лапласа и Центральной предельной теоремой.

\begin{proof}

Приведем доказательство теоремы.
Обозначим
\[
p(y_1, \ldots, y_{\sS}) = p(x_1 = y_1, \ldots, x_{\sS} = y_{\sS}).
\]
Пусть $x_1 + \ldots + x_{\sS} = y_{\sS}$ для $y_{\sS}$ из $\{1, \ldots, \sS\}$.
Тогда для произвольной перестановки $(\tau(1), \ldots, \tau(\sS))$ индексов $(1, \ldots, \sS)$ выполнено, что
\[
p(x_1 + \ldots + x_{\sS} = y_{\sS}) = C^{y_{\sS}}_{\sS} p(x_{\tau(1)}, \ldots, x_{\tau(\sS)}).
\]
Или 
\[
p(x_{\tau(1)}, \ldots, x_{\tau(\sS)}) = 
\frac{1}{C^{y_{\sS}}_{\sS}} p(x_1 + \ldots + x_{\sS} = y_{\sS}).
\]
Для произвольного $N$, такого что $N \geq \sS \geq y_{\sS} \geq 0$
выполнено, что
\begin{align*}
&p(x_1 + \ldots + x_{\sS} = y_{\sS}) =\\
&= \sum_{y_{N} = y_{\sS}}^{N - (\sS - y_{\sS})} p(x_1 + \ldots + x_{\sS} = y_{\sS} | x_1 + \ldots + x_{N} = y_{N}) p(x_1 + \ldots + x_{N} = y_{N}) = \\
&= \sum_{y_{N} = y_{\sS}}^{N - (\sS - y_{\sS})} \frac{C_{y_N}^{y_\sS} C_{N - y_{\sS}}^{\sS - y_\sS}}{C_N^\sS} p(x_1 + \ldots + x_{N} = y_{N}).
\end{align*}
Для фиксированного значения $x_1 + \ldots + x_{N}$ мы можем записать условную вероятность, используя биномиальные коэффициенты, в силу перестановочности случайных величин.
То есть, мы можем записать ее как вероятность достать из урны с $N$ шарами, $y_N$ из которых белые, а $N - y_n$ черные, $\sS$ шаров так, что из них $y_{\sS}$ белых.

Перепишем теперь 
\[
\frac{C_{y_N}^{y_\sS} C_{N - y_{\sS}}^{\sS - y_\sS}}{C_N^\sS} = C^{y_\sS}_{\sS} \frac{(y_N)_{y_\sS} (N - y_N)_{\sS - y_\sS}}{(N)_\sS},
\]
где $(N)_{\sS} = \frac{N!}{(N - n)!}$.

Таким образом, 
\begin{align*}
&p(x_{\tau(1)}, \ldots, x_{\tau(\sS)}) = 
\frac{1}{C^{y_{\sS}}_{\sS}} p(x_1 + \ldots + x_{\sS} = y_{\sS}) = \\
&= \frac{1}{C^{y_{\sS}}_{\sS}} \sum_{y_{N} = y_{\sS}}^{N - (\sS - y_{\sS})} C^{y_\sS}_{\sS} \frac{(y_N)_{y_\sS} (N - y_N)_{\sS - y_\sS}}{(N)_\sS} p(x_1 + \ldots + x_{N} = y_{N}) = \\
&= \sum_{y_{N} = y_{\sS}}^{N - (\sS - y_{\sS})} \frac{(y_N)_{y_\sS} (N - y_N)_{\sS - y_\sS}}{(N)_\sS} p(x_1 + \ldots + x_{N} = y_{N})
\end{align*}

Пусть $\Pi_N(\theta)$ совпадает с функцией распределения $x_1 + \ldots + x_{N}$, деленной на $N$.
То есть, для $\theta < 0$ функция $\Pi_N(\theta) = 0$, в точках $\theta = \frac{y_N}{N}$ она испытывает скачок, равный $p(x_1 + \ldots + x_{N} = y_{N})$, и не меняется в других точках.

Тогда 
\[
p(x_{\tau(1)}, \ldots, x_{\tau(\sS)}) = \int_{0}^1 
\frac{(\theta N)_{y_\sS} ((1 - \theta) N)_{\sS - y_\sS}}{(N)_\sS} d \Pi_N(\theta).
\]
Для $N \rightarrow \infty$ выполнено, что
\[
\frac{(\theta N)_{y_\sS} ((1 - \theta) N)_{\sS - y_\sS}}{(N)_\sS} \rightarrow \theta^{y_\sS} (1 - \theta)^{\sS - y_\sS}
\]
% Approximation of a hypergeometric probability by a
% binomial probability, c.f., G. Blom, G. Englund et.al. kap. 7.3.
Действительно, для малых $\frac{n}{N}$ получаем:
\begin{align*}
\frac{C^k_{N \theta} C^{n - k}_{N (1 - \theta)}}{C^n_N} &= 
\frac{N \theta!}{k! (N \theta - k)!} 
\frac{N (1 - \theta)!}{(n - k)! (N (1 - \theta) - (n - k)!}  \frac{n! (N - n)!}{N!} = \\
&= \frac{n!}{k! (n - k)!} \frac{(N \theta)! (N (1 - \theta))! (N - n)!}{(N \theta - k)! (N(1 - \theta) - (n - k))! N!} \approx \\
&\approx \frac{n!}{k! (n - k)!}  \frac{(N \theta)^k (N(1 - \theta))^{n - k}}{N^n} = C_n^k \theta^k (1 - \theta)^{n - k}.
\end{align*}

В соответствии с теоремой Хейли из последовательности $\{\Pi_N(\theta)\}$ можно выбрать сходящуюся подпоследовательность.
%причем в нашем случае она может иметь вид только $\theta^k (1 - \theta)^{n - k}$.

Таким образом, переходя к пределу по этой сходящейся подпоследовательности, получаем:
\[
p(x_{1}, \ldots, x_{\sS}) = \int_{0}^1 \theta^{y_n} (1 - \theta)^{n - y_n} d\Pi(\theta),
\]
причем $\Pi(\theta) = \lim_{n \rightarrow \infty} p\left(\frac{\sum_{i = 1}^n x_i}{n} \leq \theta\right)$.

\end{proof}

Приведем теперь формулировку теоремы Де Финетти в более общем виде.
\begin{Theorem}
Пусть $x_i$ составляют бесконечную перестановочную последовательность с вероятностной мерой $P$. 
% Тогда для некоторого распределения $\Pi(\theta)$ из $\mathcal{F}$ --- множества всех вероятностных распределений на $\bbR$ 
Тогда совместное распределение $p(x_1 = y_1, \ldots, x_{\sS} = y_{\sS})$ можно представить в виде:
\[
p(x_1 = y_1, \ldots, x_{\sS} = y_{\sS}) = \int_{\mathcal{F}} \prod_{i = 1}^{\sS} F(y_i) d \Pi(\theta),
\]
где $F$ --- неизвестная или ненаблюдаемая функция распределения, и
\[
\Pi(\theta) = \lim_{\sS \rightarrow \infty} P_{\sS}(\hat{F}_{\sS})
\]
--- вероятностная мера на пространстве функций $\mathcal{F}$,
определенная как предел при $\sS \rightarrow \infty$ на эмпирической функции распределения $\hat{F}_{\sS}$.

\end{Theorem}

\subsection{Выводы}

Таким образом, в Байесовской статистике действительно есть что изучать:
с одной стороны во многих случаях Байесовский подход кажется осмысленным,
с другой --- интуитивных идей недостаточно для построения стройной теории.

% В этом разделе были представлены два фундаментальных результата Байесовской статистики: теорема Де Финетти, утверждающая, что правильное подобранное априорное распределение способно сильно упростить задачу вывода, и что такое распределение всегда есть, и теорема Бернштейна-фон Мизеса, утверждающая, что Байесовская оценка будет не сильно отличаться от оценки максимума правдоподобия.
